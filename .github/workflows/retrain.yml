name: retrain-on-new-data

on:
  repository_dispatch:
    types: [s3-data-arrived]   # must match what Lambda sends

jobs:
  retrain:
    runs-on: ubuntu-latest
    permissions:
      id-token: write          # for AWS OIDC
      contents: read
    env:
      AWS_REGION: us-east-1

    steps:
      - uses: actions/checkout@v4

      # Configure AWS creds via OIDC (recommended over long-lived keys)
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::251345874268:role/GitHubOIDC-MLops
          aws-region: ${{ env.AWS_REGION }}

      # Optional: Python deps (not required for just 'aws s3 ls', but harmless)
      - name: Python deps
        run: |
          python -m pip install --upgrade pip
          pip install "boto3==1.*" "awscli==1.*"

      # Show the payload we received from Lambda
      - name: Show payload
        run: |
          echo "S3_BUCKET=${{ github.event.client_payload.s3_bucket }}"
          echo "S3_PREFIX=${{ github.event.client_payload.s3_prefix }}"

      #  Option B: simple S3 smoke test (no pipelines/run.py)
      - name: Smoke test S3 (list files under prefix)
        run: |
          BUCKET="${{ github.event.client_payload.s3_bucket }}"
          PREFIX="${{ github.event.client_payload.s3_prefix }}"
          echo "Listing s3://$BUCKET/$PREFIX"
          aws s3 ls "s3://$BUCKET/$PREFIX" --recursive
